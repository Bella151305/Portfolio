{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predict TripAdvisor Rating","metadata":{}},{"cell_type":"markdown","source":"In this competition we're provided with:\n- train and test datasets of 40,000 and 10,000 samples respectivly and 9 features except target feature;\n- target feature is **Rating** - discrete number.\n- model with hyperparameters that we're **not allowed** to change (**RandomForestRegressor**: {'bootstrap': **True**, 'criterion': '**mse**', 'max_features': '**auto**', 'n_estimators': 100});\n- baseline that gives **MAE** = 0.212\n\n**What has been done**:\n1. New features:\n    - restaurant type, area food, country food, spcialities were get from cuisine style feature\n    - name of restaurant and its region were get from url\n    - chain and chain_scale were get by grouping restaurants' names\n    - lasts 2 reviews date delta and last review date delta with max date of review as well as positive and negative words scores were get from reviews feature\n    - some normalized and scaled be city numerical features\n    - some means and medians\n    - polinomial features\n    - dummy features\n2. 27 tests of model with different features conbinations\n3. **MAE** has been reduced to **0.198** and after rounding predict with pitch 0.5 to make continious number discrete - to **0.168** on validation data (**0.1726** on the submission)\n\n- For data investigation results go to 'Bella K [SF TripAdvisor Rating] EDA+NaNs'\n- For models testing results go to 'Bella K [SF TripAdvisor Rating] FE+Models'","metadata":{}},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-22T06:50:22.576195Z","iopub.execute_input":"2023-05-22T06:50:22.576655Z","iopub.status.idle":"2023-05-22T06:50:22.599276Z","shell.execute_reply.started":"2023-05-22T06:50:22.576589Z","shell.execute_reply":"2023-05-22T06:50:22.597703Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/sf-dst-restaurant-rating/sample_submission.csv\n/kaggle/input/sf-dst-restaurant-rating/main_task.csv\n/kaggle/input/sf-dst-restaurant-rating/kaggle_task.csv\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/model_data.csv\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/best_model.pkl\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/data_for_model.csv\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__results__.html\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__notebook_source__.ipynb\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/requirements.txt\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__notebook__.ipynb\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/lists_dict.json\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__output__.json\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/custom.css\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__results___files/__results___23_4.png\n/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/__results___files/__results___24_2.png\n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import rcParams\n#%config InlineBackend.figure_format = 'svg' # graphs in svg look clearer\nplt.style.use('ggplot')  # beautiful graphs\nplt.rcParams['figure.figsize'] = (12, 4)  # figure size\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom datetime import datetime\nfrom datetime import date\n\nimport json","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:48:08.857921Z","iopub.execute_input":"2023-05-22T06:48:08.858260Z","iopub.status.idle":"2023-05-22T06:48:08.866506Z","shell.execute_reply.started":"2023-05-22T06:48:08.858191Z","shell.execute_reply":"2023-05-22T06:48:08.865489Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# make our experiments reproducible\nRANDOM_SEED = 42\nCURRENT_DATE = pd.to_datetime(date.today().strftime('%Y-%m-%d'))\nCURRENT_DATE","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:48:08.939106Z","iopub.execute_input":"2023-05-22T06:48:08.939683Z","iopub.status.idle":"2023-05-22T06:48:08.950450Z","shell.execute_reply.started":"2023-05-22T06:48:08.939632Z","shell.execute_reply":"2023-05-22T06:48:08.949359Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Timestamp('2023-05-22 00:00:00')"},"metadata":{}}]},{"cell_type":"code","source":"# fix the version of the packages\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:48:10.441583Z","iopub.execute_input":"2023-05-22T06:48:10.442007Z","iopub.status.idle":"2023-05-22T06:48:13.478571Z","shell.execute_reply.started":"2023-05-22T06:48:10.441949Z","shell.execute_reply":"2023-05-22T06:48:13.477325Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n#df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n\nprint('Size of the test dataset:', df_test.shape)\nprint('Size of the submission dataset:', sample_submission.shape, end='\\n\\n')\n\nmodel_data = pd.read_csv('/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/model_data.csv')\nprint('Size of the model dataset:', model_data.shape)\n\nwith open('/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/lists_dict.json', 'rb') as infile:\n    lists_dict = json.load(infile)\n    \nlen(lists_dict['rest_type_list'])","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-05-22T06:50:30.526970Z","iopub.execute_input":"2023-05-22T06:50:30.527357Z","iopub.status.idle":"2023-05-22T06:50:31.394382Z","shell.execute_reply.started":"2023-05-22T06:50:30.527294Z","shell.execute_reply":"2023-05-22T06:50:31.393229Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Size of the test dataset: (10000, 9)\nSize of the submission dataset: (10000, 2)\n\nSize of the model dataset: (40000, 74)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"19"},"metadata":{}}]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:50:37.055028Z","iopub.execute_input":"2023-05-22T06:50:37.055376Z","iopub.status.idle":"2023-05-22T06:50:37.075434Z","shell.execute_reply.started":"2023-05-22T06:50:37.055325Z","shell.execute_reply":"2023-05-22T06:50:37.074345Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  Restaurant_id        City  \\\n0          id_0       Paris   \n1          id_1    Helsinki   \n2          id_2   Edinburgh   \n3          id_3      London   \n4          id_4  Bratislava   \n\n                                       Cuisine Style  Ranking Price Range  \\\n0                                     ['Bar', 'Pub']  12963.0    $$ - $$$   \n1  ['European', 'Scandinavian', 'Gluten Free Opti...    106.0    $$ - $$$   \n2                            ['Vegetarian Friendly']    810.0    $$ - $$$   \n3  ['Italian', 'Mediterranean', 'European', 'Vege...   1669.0        $$$$   \n4  ['Italian', 'Mediterranean', 'European', 'Seaf...     37.0        $$$$   \n\n   Number of Reviews                                            Reviews  \\\n0                4.0                                           [[], []]   \n1               97.0  [['Very good reviews!', 'Fine dining in Hakani...   \n2               28.0  [['Better than the Links', 'Ivy Black'], ['12/...   \n3              202.0  [['Most exquisite', 'Delicious and authentic']...   \n4              162.0  [['Always the best in bratislava', 'Very good ...   \n\n                                              URL_TA      ID_TA  \n0  /Restaurant_Review-g187147-d10746918-Reviews-L...  d10746918  \n1  /Restaurant_Review-g189934-d6674944-Reviews-Ra...   d6674944  \n2  /Restaurant_Review-g186525-d13129638-Reviews-B...  d13129638  \n3  /Restaurant_Review-g186338-d680417-Reviews-Qui...    d680417  \n4  /Restaurant_Review-g274924-d1112354-Reviews-Ma...   d1112354  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant_id</th>\n      <th>City</th>\n      <th>Cuisine Style</th>\n      <th>Ranking</th>\n      <th>Price Range</th>\n      <th>Number of Reviews</th>\n      <th>Reviews</th>\n      <th>URL_TA</th>\n      <th>ID_TA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_0</td>\n      <td>Paris</td>\n      <td>['Bar', 'Pub']</td>\n      <td>12963.0</td>\n      <td>$$ - $$$</td>\n      <td>4.0</td>\n      <td>[[], []]</td>\n      <td>/Restaurant_Review-g187147-d10746918-Reviews-L...</td>\n      <td>d10746918</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_1</td>\n      <td>Helsinki</td>\n      <td>['European', 'Scandinavian', 'Gluten Free Opti...</td>\n      <td>106.0</td>\n      <td>$$ - $$$</td>\n      <td>97.0</td>\n      <td>[['Very good reviews!', 'Fine dining in Hakani...</td>\n      <td>/Restaurant_Review-g189934-d6674944-Reviews-Ra...</td>\n      <td>d6674944</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_2</td>\n      <td>Edinburgh</td>\n      <td>['Vegetarian Friendly']</td>\n      <td>810.0</td>\n      <td>$$ - $$$</td>\n      <td>28.0</td>\n      <td>[['Better than the Links', 'Ivy Black'], ['12/...</td>\n      <td>/Restaurant_Review-g186525-d13129638-Reviews-B...</td>\n      <td>d13129638</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_3</td>\n      <td>London</td>\n      <td>['Italian', 'Mediterranean', 'European', 'Vege...</td>\n      <td>1669.0</td>\n      <td>$$$$</td>\n      <td>202.0</td>\n      <td>[['Most exquisite', 'Delicious and authentic']...</td>\n      <td>/Restaurant_Review-g186338-d680417-Reviews-Qui...</td>\n      <td>d680417</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_4</td>\n      <td>Bratislava</td>\n      <td>['Italian', 'Mediterranean', 'European', 'Seaf...</td>\n      <td>37.0</td>\n      <td>$$$$</td>\n      <td>162.0</td>\n      <td>[['Always the best in bratislava', 'Very good ...</td>\n      <td>/Restaurant_Review-g274924-d1112354-Reviews-Ma...</td>\n      <td>d1112354</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:50:38.960025Z","iopub.execute_input":"2023-05-22T06:50:38.960442Z","iopub.status.idle":"2023-05-22T06:50:38.972345Z","shell.execute_reply.started":"2023-05-22T06:50:38.960372Z","shell.execute_reply":"2023-05-22T06:50:38.971421Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  Restaurant_id  Rating\n0          id_0     2.0\n1          id_1     2.5\n2          id_2     4.0\n3          id_3     1.0\n4          id_4     4.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant_id</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_1</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_2</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_4</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:50:40.354113Z","iopub.execute_input":"2023-05-22T06:50:40.354448Z","iopub.status.idle":"2023-05-22T06:50:40.390375Z","shell.execute_reply.started":"2023-05-22T06:50:40.354405Z","shell.execute_reply":"2023-05-22T06:50:40.389372Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"  restaurant_id       city                                      cuisine_style  \\\n0       id_5569      Paris            ['European', 'French', 'International']   \n1       id_1535  Stockholm                                                NaN   \n2        id_352     London  ['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...   \n3       id_3456     Berlin                                                NaN   \n4        id_615     Munich  ['German', 'Central European', 'Vegetarian Fri...   \n\n   ranking  rating  price_range  number_of_reviews  \\\n0   5570.0     3.5          2.5              194.0   \n1   1537.0     4.0          2.5               10.0   \n2    353.0     4.5          4.0              688.0   \n3   3458.0     5.0          2.5                3.0   \n4    621.0     4.0          2.5               84.0   \n\n                                             reviews  \\\n0  [\"'Good food at your doorstep', 'A good hotel ...   \n1  [\"'Unique cuisine', 'Delicious Nepalese food'\"...   \n2  [\"'Catch up with friends', 'Not exceptional'\",...   \n3                                                NaN   \n4  [\"'Best place to try a Bavarian food', 'Nice b...   \n\n                                              url_ta     id_ta  ...  \\\n0  /Restaurant_Review-g187147-d1912643-Reviews-R_...  d1912643  ...   \n1  /Restaurant_Review-g189852-d7992032-Reviews-Bu...  d7992032  ...   \n2  /Restaurant_Review-g186338-d8632781-Reviews-RO...  d8632781  ...   \n3  /Restaurant_Review-g187323-d1358776-Reviews-Es...  d1358776  ...   \n4  /Restaurant_Review-g187309-d6864963-Reviews-Au...  d6864963  ...   \n\n   city_cheap  city_medium city_expensive city_chain_scaled city_cheap_scaled  \\\n0         594         4065            238          0.114968          0.121299   \n1          52          743             25          0.080488          0.063415   \n2        1064         4479            214          0.159458          0.184818   \n3         340         1766             49          0.090023          0.157773   \n4          91          761             41          0.124300          0.101904   \n\n   city_medium_scaled  city_expensive_scaled  rev_num_city_scaled_old  \\\n0            0.830100               0.048601                     0.04   \n1            0.906098               0.030488                     0.01   \n2            0.778009               0.037172                     0.12   \n3            0.819490               0.022738                     0.00   \n4            0.852184               0.045913                     0.09   \n\n  reviews_pos_score reviews_neg_score  \n0               1.0               0.0  \n1               0.0               0.0  \n2               0.0               0.0  \n3               NaN               NaN  \n4               0.0               0.0  \n\n[5 rows x 74 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>restaurant_id</th>\n      <th>city</th>\n      <th>cuisine_style</th>\n      <th>ranking</th>\n      <th>rating</th>\n      <th>price_range</th>\n      <th>number_of_reviews</th>\n      <th>reviews</th>\n      <th>url_ta</th>\n      <th>id_ta</th>\n      <th>...</th>\n      <th>city_cheap</th>\n      <th>city_medium</th>\n      <th>city_expensive</th>\n      <th>city_chain_scaled</th>\n      <th>city_cheap_scaled</th>\n      <th>city_medium_scaled</th>\n      <th>city_expensive_scaled</th>\n      <th>rev_num_city_scaled_old</th>\n      <th>reviews_pos_score</th>\n      <th>reviews_neg_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_5569</td>\n      <td>Paris</td>\n      <td>['European', 'French', 'International']</td>\n      <td>5570.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>194.0</td>\n      <td>[\"'Good food at your doorstep', 'A good hotel ...</td>\n      <td>/Restaurant_Review-g187147-d1912643-Reviews-R_...</td>\n      <td>d1912643</td>\n      <td>...</td>\n      <td>594</td>\n      <td>4065</td>\n      <td>238</td>\n      <td>0.114968</td>\n      <td>0.121299</td>\n      <td>0.830100</td>\n      <td>0.048601</td>\n      <td>0.04</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_1535</td>\n      <td>Stockholm</td>\n      <td>NaN</td>\n      <td>1537.0</td>\n      <td>4.0</td>\n      <td>2.5</td>\n      <td>10.0</td>\n      <td>[\"'Unique cuisine', 'Delicious Nepalese food'\"...</td>\n      <td>/Restaurant_Review-g189852-d7992032-Reviews-Bu...</td>\n      <td>d7992032</td>\n      <td>...</td>\n      <td>52</td>\n      <td>743</td>\n      <td>25</td>\n      <td>0.080488</td>\n      <td>0.063415</td>\n      <td>0.906098</td>\n      <td>0.030488</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_352</td>\n      <td>London</td>\n      <td>['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...</td>\n      <td>353.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>688.0</td>\n      <td>[\"'Catch up with friends', 'Not exceptional'\",...</td>\n      <td>/Restaurant_Review-g186338-d8632781-Reviews-RO...</td>\n      <td>d8632781</td>\n      <td>...</td>\n      <td>1064</td>\n      <td>4479</td>\n      <td>214</td>\n      <td>0.159458</td>\n      <td>0.184818</td>\n      <td>0.778009</td>\n      <td>0.037172</td>\n      <td>0.12</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_3456</td>\n      <td>Berlin</td>\n      <td>NaN</td>\n      <td>3458.0</td>\n      <td>5.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>/Restaurant_Review-g187323-d1358776-Reviews-Es...</td>\n      <td>d1358776</td>\n      <td>...</td>\n      <td>340</td>\n      <td>1766</td>\n      <td>49</td>\n      <td>0.090023</td>\n      <td>0.157773</td>\n      <td>0.819490</td>\n      <td>0.022738</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_615</td>\n      <td>Munich</td>\n      <td>['German', 'Central European', 'Vegetarian Fri...</td>\n      <td>621.0</td>\n      <td>4.0</td>\n      <td>2.5</td>\n      <td>84.0</td>\n      <td>[\"'Best place to try a Bavarian food', 'Nice b...</td>\n      <td>/Restaurant_Review-g187309-d6864963-Reviews-Au...</td>\n      <td>d6864963</td>\n      <td>...</td>\n      <td>91</td>\n      <td>761</td>\n      <td>41</td>\n      <td>0.124300</td>\n      <td>0.101904</td>\n      <td>0.852184</td>\n      <td>0.045913</td>\n      <td>0.09</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 74 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# FUNCTIONS\n\nimport collections\n\n# count the number of mentions of unique values and get those that come across more than 1 time\ndef collect_repeated_items(col):\n    c = collections.Counter()\n    for el in data[col].tolist():\n        c[el]+=1\n    print('Unique values:', len(c))\n    \n    new_c = {k: v for k, v in c.items() if v > 1}\n    print('Values repeated more then one time:', len(new_c))\n    \n    c_list = list(new_c.keys())\n    \n    return c_list\n\n\n\nimport math\n\n# divide all restaurants into conditional groups by frequency of occurrence\ndef get_param_scale(cell):\n    for el in percentile_75_list:\n        if cell < el+1:\n            cell = el\n            break\n    \n    return cell\n\n\n# take the percentile as a criterion\ndef get_percentile(pc, df, col):\n    percentile_list = []\n    percentile = 0\n    col_max = max(df[col])\n\n    while math.ceil(col_max) > math.ceil(percentile):\n        percentile = math.ceil(np.percentile(df.loc[(df[col]>percentile)][col], pc))\n        percentile_list.append(percentile)\n        \n    return percentile_list\n\n\n\n# in the case of chain==1, rest_type, area_food, country_food, specialties will be filled with mods by city and name\ndef get_mode(col):\n\n    city_name_dict_1 = {}\n    for city in model_data.city.unique():\n        city_name_dict_1.update({city: {'name': model_data.loc[(model_data['city']==city)&(model_data['chain']==1)&(model_data['name'].isna()==False)].groupby('name')[col].apply(lambda x: x.mode()).reset_index().to_dict('index')}})\n\n    city_name_dict_1 = {k: v['name'] for k, v in city_name_dict_1.items()}\n    city_name_dict_1 = {key: {v['name']: v[col] for k, v in city_name_dict_1[key].items()} for key, value in city_name_dict_1.items()}\n\n    city_name_dict_0 = {}\n    for city in df_test.city.unique():\n        city_name_dict_0.update({city: {'name': df_test.loc[(df_test['city']==city)&(df_test['chain']==1)&(df_test['name'].isna()==False)].groupby('name')[col].apply(lambda x: x.mode()).reset_index().to_dict('index')}})\n\n    city_name_dict_0 = {k: v['name'] for k, v in city_name_dict_0.items()}\n    city_name_dict_0 = {key: {v['name']: v[col] for k, v in city_name_dict_0[key].items()} for key, value in city_name_dict_0.items()}\n\n    return city_name_dict_1, city_name_dict_0\n    # {'Paris': {'231_east_street': 'Fast Food', ...}}\n    \n    \n# in case of chain==0 rest_type_count, area_food_court, country_food_count, specialities_count\n# fill in median by city and price_range\ndef get_median(col):\n\n    city_price_dict_1 = {}\n    for city in model_data.city.unique():\n        city_price_dict_1.update({city: {'price_range': model_data.loc[(model_data['city']==city)&(model_data['chain']==0)&(model_data['name'].isna()==False)].groupby('price_range')[col].median().reset_index().to_dict('index')}})\n\n    city_price_dict_1 = {k: v['price_range'] for k, v in city_price_dict_1.items()}\n    city_price_dict_1 = {key: {v['price_range']: round(v[col], 0) for k, v in city_price_dict_1[key].items()} for key, value in city_price_dict_1.items()}\n\n    city_price_dict_0 = {}\n    for city in df_test.city.unique():\n        city_price_dict_0.update({city: {'price_range': df_test.loc[(df_test['city']==city)&(df_test['chain']==0)&(df_test['name'].isna()==False)].groupby('price_range')[col].median().reset_index().to_dict('index')}})\n\n    city_price_dict_0 = {k: v['price_range'] for k, v in city_price_dict_0.items()}\n    city_price_dict_0 = {key: {v['price_range']: round(v[col], 0) for k, v in city_price_dict_0[key].items()} for key, value in city_name_dict_0.items()}\n\n    return city_price_dict_1, city_price_dict_0\n    # 'Krakow': {1.0: 1.0, 2.5: 1.0, 4.0: 2.0}\n    \n    \n    \nfrom itertools import product\n\ndef get_stat_dict(df, cat, num, stat): # stat_list = ['mean', 'median', 'std', 'quant_25', 'quant_75']\n    cat_num_dict = {}\n    \n    if stat=='mean':\n        for city in df.city.unique():\n            try:\n                cat_num_dict.update({city: {str(cat): df.loc[df['city']==city].groupby(cat)[num].mean().reset_index().to_dict('index')}})\n            except: pass\n        \n    elif stat=='median':\n        for city in df.city.unique():\n            try:\n                cat_num_dict.update({city: {str(cat): df.loc[df['city']==city].groupby(cat)[num].median().reset_index().to_dict('index')}})\n            except: pass\n        \n    cat_num_dict = {k: v[str(cat)] for k, v in cat_num_dict.items()}\n    cat_num_dict = {key: {v[str(cat)]: round(v[str(num)], 2) for k, v in cat_num_dict[key].items()} for key, value in cat_num_dict.items()}\n    \n    return cat_num_dict\n\n\n\n# make a dictionary of the Cuisine Style frequency taking into account a certain parameter\ndef cuisine_count_dict(cell):\n    c = collections.Counter()\n    for el in cell:\n        if el is not np.nan:\n            if type(el)==list:\n                for x in el:\n                    c[x]+=1\n            else:\n                c[el]+=1\n    \n    c = {k: v for k, v in sorted(c.items(), key=by_value, reverse=True)}\n    return c\n\n\n# sort the dictionary in descending order of quantity\ndef by_value(item):\n    return item[1]\n\n\ndef find_item(cell):\n    if item in cell:\n        return 1\n    return 0\n\n\n\n# count the number of positive and negative words in the reviews\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\n\ndef get_words_list(cell):\n    cell_text = ' '.join(cell)\n    cell_text_new = re.sub(r'[.,?!:;()=-_\\'\\\"]', '', cell_text)\n    cell_words_list = cell_text_new.split(' ')\n    cell_words_list = [w.strip() for w in cell_words_list if len(w) > 1 ]\n    cell_words_list = [w.strip() for w in cell_words_list if w not in stopwords.words('english')]\n    \n    return cell_words_list\n\n\ndef get_positive_score(cell):\n    cell_score = sum([1 for w in cell if w in lists_dict['pos_list']])\n    \n    return cell_score\n\n\ndef get_negative_score(cell):\n    cell_score = sum([1 for w in cell if w in lists_dict['neg_list']])\n    \n    return cell_score\n\n\n\ndef get_data_columns(list_of_lists):\n    columns_list = []\n    for el in list_of_lists:\n        columns_list.extend(el)\n        \n    return columns_list\n\n\ndef remove_elments(old_list, el_list):\n    for el in el_list:\n        old_list.remove(el)\n        \n    return old_list\n\n\ndef get_data_columns_dict(list_of_names):\n    columns_list = []\n    for name in list_of_names:\n        for el in features_dict[name]:\n            columns_list.extend([el])\n            \n    return columns_list\n\n\ndef features_dict_update(feature_list_name, new_feature):\n    feature_list = features_dict[feature_list_name]\n    feature_list.extend([new_feature])\n    features_dict.update({feature_list_name: feature_list})\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:48:21.863532Z","iopub.execute_input":"2023-05-22T06:48:21.863969Z","iopub.status.idle":"2023-05-22T06:48:22.200938Z","shell.execute_reply.started":"2023-05-22T06:48:21.863910Z","shell.execute_reply":"2023-05-22T06:48:22.199872Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# IMPORTANT!!! Everything is calculated according to train and transferred to test\n# and only if there is no such combination in train, then it is calculated according to test df_test\n\n#def preproc_test_data(df_input, model_data):\n    \n    # DATA\n    #df_output = df_input.copy()\n    \nprint('Data processing started')\n    \ndf_test['Rating'] = 0 # in test we don't have column Rating, it's our target\ndf_test.columns = [x.lower().replace(' ', '_') for x in df_test.columns]\n\n# the structure of the list, but the data type is a string\n# turn it into a list\ndf_test['cuisine_style'] = df_test['cuisine_style'].dropna().apply(lambda x: x[2:-2].split(\"', '\"))\n# count the number of kitchens\ndf_test['cuisine_style_count'] = df_test['cuisine_style'].dropna().apply(lambda x: len(x))\n\ndf_test['price_range'] = df_test['price_range'].dropna().apply(lambda x: 1.0 if x=='$' else (2.5 if x=='$$ - $$$' else(4.0 if x=='$$$$' else x)))\n\n    \ncity_count_1 = model_data['city'].value_counts()\ncity_count_0 = df_test['city'].value_counts()\ndf_test['city_count'] = df_test['city'].dropna().apply(lambda x: city_count_1[x] if x in city_count_1.index else (city_count_0[x] if x in city_count_0.index else np.nan))\n\n    \n# get the data about the name of the restaurant (or chain?), the region and some other g-code from URL_TA\ndf_test['name'] = df_test['url_ta'].dropna().apply(lambda x: x.split('-')[4].replace('.html', ''))\ndf_test['region'] = df_test['url_ta'].dropna().apply(lambda x: x.split('-')[5].replace('.html', '') if len(x.split('-'))>5 else x.split('-')[4].replace('.html', ''))\ndf_test['g_code'] = df_test['url_ta'].dropna().apply(lambda x: x.split('-')[1])\n# in some cases, there is no indication of the name, then the region is pulled up - let's fix it\ndf_test.iloc[df_test.loc[df_test['name'] == df_test['region']].index.tolist(), df_test.columns.tolist().index('name')] = np.nan\ndf_test['name'] = df_test['name'].dropna().apply(lambda x: x.lower())\ndf_test['region'] = df_test['region'].dropna().apply(lambda x: x.lower())\n\n    \nname_count_1 = model_data.loc[(model_data['name'].isna()==False)]['name'].value_counts()\nname_count_0 = df_test.loc[(df_test['name'].isna()==False)]['name'].value_counts()\ndf_test['name_count'] = df_test['name'].apply(lambda x: name_count_1[x] if x in name_count_1.index else (name_count_0[x] if x in name_count_0.index else 1))\n    \nmodel_data['name_count'] = model_data['name'].apply(lambda x: name_count_1[x] if x in name_count_1.index else 1)\n\n    \ndf_test['chain'] = df_test['name_count'].dropna().apply(lambda x: 0 if x==1 else 1)\n# take 75 percentile as a criterion\npercentile_75_list = get_percentile(75, model_data, 'name_count') # chain_scale\ndf_test['chain_scale'] = df_test['name_count'].dropna().apply(get_param_scale)\n\n    \ngcode_count_1 = model_data['g_code'].value_counts()\ngcode_count_0 = df_test['g_code'].value_counts()\ndf_test['gcode_count'] = df_test['g_code'].dropna().apply(lambda x: gcode_count_1[x] if x in gcode_count_1.index else (gcode_count_0[x] if x in gcode_count_0.index else np.nan))\n\n\n# the structure of the lists in the list (review and dates), but the data type is a string\n# turning empty lists into nan and strings into lists\ndf_test['reviews'] = df_test['reviews'].dropna().apply(lambda x: np.nan if x == '[[], []]' else x[2:-2].split(\"], [\"))\n\n# at the same time, we separate the review and turn the data into lists\ndf_test['reviews_text'] = df_test['reviews'].dropna().apply(lambda x: x[0][1:-1].split(\"', '\"))\n\n# separate the dates from the review and turn the data into lists\ndf_test['reviews_date'] = df_test['reviews'].dropna().apply(lambda x: x[1][1:-1].split(\"', '\"))\n# turning strings into dates\ndf_test['reviews_date'] = df_test['reviews_date'].dropna().apply(lambda x: [pd.to_datetime(i) for i in x])\ndf_test['reviews_date_last'] = df_test['reviews_date'].dropna().apply(lambda x: max(x))\n    \nmodel_data['reviews_date_last'] = model_data['reviews_date_last'].dropna().apply(lambda x: pd.to_datetime(x))\n    \n    \nreviews_date_max = max([max(model_data['reviews_date_last'].dropna().tolist()), max(df_test['reviews_date_last'].dropna().tolist())])\ndf_test['reviews_date_delta'] = df_test['reviews_date'].dropna().apply(lambda x: (max(x) - min(x)).days)\ndf_test['reviews_date_delta_max'] = df_test['reviews_date'].dropna().apply(lambda x: (reviews_date_max - max(x)).days)\n\n    \n# divide cuisine_style\ndf_test['rest_type'] = df_test['cuisine_style'].dropna().apply(lambda x: [st for st in lists_dict['rest_type_list'] if st in x])\ndf_test['rest_type_count'] = df_test['rest_type'].dropna().apply(lambda x: len(x))\ndf_test['rest_type'] = df_test['rest_type'].dropna().apply(lambda x: ', '.join(x) if len(x)>0 else np.nan)\n\ndf_test['area_food'] = df_test['cuisine_style'].dropna().apply(lambda x: [st for st in lists_dict['area_food_list'] if st in x])\ndf_test['area_food_count'] = df_test['area_food'].dropna().apply(lambda x: len(x))\ndf_test['area_food'] = df_test['area_food'].dropna().apply(lambda x: ', '.join(x) if len(x)>0 else np.nan)\n\ndf_test['country_food'] = df_test['cuisine_style'].dropna().apply(lambda x: [st for st in lists_dict['country_food_list'] if st in x])\ndf_test['country_food_count'] = df_test['country_food'].dropna().apply(lambda x: len(x))\ndf_test['country_food'] = df_test['country_food'].dropna().apply(lambda x: ', '.join(x) if len(x)>0 else np.nan)\n\ndf_test['spcialities'] = df_test['cuisine_style'].dropna().apply(lambda x: [st for st in lists_dict['spcialities_list'] if st in x])\ndf_test['spcialities_count'] = df_test['spcialities'].dropna().apply(lambda x: len(x))\ndf_test['spcialities'] = df_test['spcialities'].dropna().apply(lambda x: ', '.join(x) if len(x)>0 else np.nan)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:50:47.115237Z","iopub.execute_input":"2023-05-22T06:50:47.115767Z","iopub.status.idle":"2023-05-22T06:50:59.124191Z","shell.execute_reply.started":"2023-05-22T06:50:47.115690Z","shell.execute_reply":"2023-05-22T06:50:59.123240Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Data processing started\n","output_type":"stream"}]},{"cell_type":"code","source":"# NaNs\n    \nprint('NaNs processing started')\n\n# price_range\n\ndef round_to_closest(number, lst=[1.0, 2.5, 4.0]):\n    return min(lst, key=lambda x: abs(x - number))\n\nprice_range_dict = {}\nfor city in model_data.city.unique():\n    price_range_dict.update({city: {'chain_scale': model_data.loc[(model_data['city']==city)].groupby('chain_scale')['price_range'].mean().reset_index().to_dict('index')}})\n        \nprice_range_dict = {k: v['chain_scale'] for k, v in price_range_dict.items()}\nprice_range_dict = {key: {v['chain_scale']: round_to_closest(v['price_range']) if math.isnan(v['price_range'])==False else np.nan for k, v in price_range_dict[key].items()} for key, value in price_range_dict.items()}\n\ndf_test['price_range_old'] = df_test['price_range']\ndf_test['price_range'] = df_test.apply(lambda x: price_range_dict[x['city']][x['chain_scale']] if math.isnan(x['price_range_old'])==True else x['price_range'], axis=1)\ndf_test['price_range'] = df_test['price_range'].fillna(2.5)\n\n    \n# number_of_reviews\n\nnum_rev_cuisine_dict = {}\nfor city in model_data.city.unique():\n    num_rev_cuisine_dict.update({city: {'cuisine_style_count': model_data.loc[(model_data['city']==city)&(model_data['cuisine_style_count'].isna()==False)].groupby('cuisine_style_count')['number_of_reviews'].median().reset_index().to_dict('index')}})\n        \nnum_rev_cuisine_dict = {k: v['cuisine_style_count'] for k, v in num_rev_cuisine_dict.items()}\nnum_rev_cuisine_dict = {key: {v['cuisine_style_count']: v['number_of_reviews'] if math.isnan(v['number_of_reviews'])==False else np.nan for k, v in num_rev_cuisine_dict[key].items()} for key, value in num_rev_cuisine_dict.items()}\n\n\nnum_rev_price_dict = {}\nfor city in model_data.city.unique():\n    num_rev_price_dict.update({city: {'price_range': model_data.loc[(model_data['city']==city)].groupby('price_range')['number_of_reviews'].median().reset_index().to_dict('index')}})\n        \nnum_rev_price_dict = {k: v['price_range'] for k, v in num_rev_price_dict.items()}\nnum_rev_price_dict = {key: {v['price_range']: v['number_of_reviews'] if math.isnan(v['number_of_reviews'])==False else np.nan for k, v in num_rev_price_dict[key].items()} for key, value in num_rev_price_dict.items()}\n\n\ndf_test['number_of_reviews_old'] = df_test['number_of_reviews']\n\ndf_test['number_of_reviews'] = df_test.apply(lambda x: num_rev_cuisine_dict[x['city']][x['cuisine_style_count']] if math.isnan(x['number_of_reviews_old'])==True and math.isnan(x['cuisine_style_count'])==False else x['number_of_reviews'], axis=1)\ndf_test['number_of_reviews'] = df_test.apply(lambda x: num_rev_price_dict[x['city']][x['price_range']] if math.isnan(x['number_of_reviews'])==True else x['number_of_reviews'], axis=1)\n\n    \n# cuisine_style\n\n# instead of name_count, let's count name_city_count\ncity_name_dict_1 = {}\nfor city in model_data.city.unique():\n    city_name_dict_1.update({city: {'name': model_data.loc[(model_data['city']==city)&(model_data['name'].isna()==False)].groupby('name')['id_ta'].count().reset_index().to_dict('index')}})\n\ncity_name_dict_1 = {k: v['name'] for k, v in city_name_dict_1.items()}\ncity_name_dict_1 = {key: {v['name']: v['id_ta'] if math.isnan(v['id_ta'])==False else np.nan for k, v in city_name_dict_1[key].items()} for key, value in city_name_dict_1.items()}\n\ncity_name_dict_0 = {}\nfor city in df_test.city.unique():\n    city_name_dict_0.update({city: {'name': df_test.loc[(df_test['city']==city)&(df_test['name'].isna()==False)].groupby('name')['id_ta'].count().reset_index().to_dict('index')}})\n\ncity_name_dict_0 = {k: v['name'] for k, v in city_name_dict_0.items()}\ncity_name_dict_0 = {key: {v['name']: v['id_ta'] if math.isnan(v['id_ta'])==False else np.nan for k, v in city_name_dict_0[key].items()} for key, value in city_name_dict_0.items()}\n\n# {'Paris': {015_gang_nam': 1}, ...}\n\ndf_test['name_city_count'] = df_test.apply(lambda x: city_name_dict_1[x['city']][x['name']] if x['name'] in list(city_name_dict_1[x['city']].keys()) else (city_name_dict_0[x['city']][x['name']] if x['name'] in list(city_name_dict_0[x['city']].keys()) else 1), axis=1)\ndf_test = df_test.drop('name_count', axis=1)\n#model_data = model_data.drop('name_count', axis=1)\n\n    \ndf_test['rest_type_old'] = df_test['rest_type']\ndf_test['area_food_old'] = df_test['area_food']\ndf_test['country_food_old'] = df_test['country_food']\ndf_test['spcialities_old'] = df_test['spcialities']\n    \n\n# in the case of chain==1 rest_type, area_food, country_food, specialties fill in with modes by city and name\ncity_name_dict_1, city_name_dict_0 = get_mode('rest_type')\ndf_test['rest_type'] = df_test.apply(lambda x: city_name_dict_1[x['city']][x['name']] if x['name'] in list(city_name_dict_1[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else (city_name_dict_0[x['city']][x['name']] if x['name'] in list(city_name_dict_0[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else x['rest_type']), axis=1)\n\ncity_name_dict_1, city_name_dict_0 = get_mode('area_food')\ndf_test['area_food'] = df_test.apply(lambda x: city_name_dict_1[x['city']][x['name']] if x['name'] in list(city_name_dict_1[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else (city_name_dict_0[x['city']][x['name']] if x['name'] in list(city_name_dict_0[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else x['area_food']), axis=1)\n\ncity_name_dict_1, city_name_dict_0 = get_mode('country_food')\ndf_test['country_food'] = df_test.apply(lambda x: city_name_dict_1[x['city']][x['name']] if x['name'] in list(city_name_dict_1[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else (city_name_dict_0[x['city']][x['name']] if x['name'] in list(city_name_dict_0[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else x['country_food']), axis=1)\n\ncity_name_dict_1, city_name_dict_0 = get_mode('spcialities')\ndf_test['spcialities'] = df_test.apply(lambda x: city_name_dict_1[x['city']][x['name']] if x['name'] in list(city_name_dict_1[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else (city_name_dict_0[x['city']][x['name']] if x['name'] in list(city_name_dict_0[x['city']].keys()) and math.isnan(x['cuisine_style_count'])==True else x['spcialities']), axis=1)\n\n# recalculate all ..._count\ndf_test['rest_type_count'] = df_test['rest_type'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['area_food_count'] = df_test['area_food'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['country_food_count'] = df_test['country_food'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['spcialities_count'] = df_test['spcialities'].dropna().apply(lambda x: len(x.split(', ')))\n\n    \n# in the case of chain==0 cuisine_style_count, rest_type_count, area_food_count, country_food_count, spcialities_count, \n# fill in with median by city and price_range\ncity_price_dict_1, city_price_dict_0 = get_median('rest_type_count')\ndf_test['rest_type_count'] = df_test.apply(lambda x: city_price_dict_1[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else (city_price_dict_0[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else x['rest_type_count']), axis=1)\n\ncity_price_dict_1, city_price_dict_0 = get_median('area_food_count')\ndf_test['area_food_count'] = df_test.apply(lambda x: city_price_dict_1[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else (city_price_dict_0[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else x['area_food_count']), axis=1)\n\ncity_price_dict_1, city_price_dict_0 = get_median('country_food_count')\ndf_test['country_food_count'] = df_test.apply(lambda x: city_price_dict_1[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else (city_price_dict_0[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else x['country_food_count']), axis=1)\n\ncity_price_dict_1, city_price_dict_0 = get_median('spcialities_count')\ndf_test['spcialities_count'] = df_test.apply(lambda x: city_price_dict_1[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else (city_price_dict_0[x['city']][x['price_range']] if math.isnan(x['cuisine_style_count'])==True else x['spcialities_count']), axis=1)\n\n# fill remain NaNs with 0 to recalculate cuisine_style_count\ndf_test['rest_type_count'] = df_test['rest_type_count'].fillna(0)\ndf_test['area_food_count'] = df_test['area_food_count'].fillna(0)\ndf_test['country_food_count'] = df_test['country_food_count'].fillna(0)\ndf_test['spcialities_count'] = df_test['spcialities_count'].fillna(0)\n\ndf_test['cuisine_style_count'] = df_test.apply(lambda x: x['rest_type_count']+x['area_food_count']+x['country_food_count']+x['spcialities_count'], axis=1)\n\n    \n# reviews_date_delta & reviews_date_delta_max\n# We will fill in the gaps not in dates, but in intervals\nrev_delta_cuisine_dict = {}\nfor city in model_data.city.unique():\n    rev_delta_cuisine_dict.update({city: {'cuisine_style_count': model_data.loc[(model_data['city']==city)].groupby('cuisine_style_count')['reviews_date_delta'].median().reset_index().to_dict('index')}})\n        \nrev_delta_cuisine_dict = {k: v['cuisine_style_count'] for k, v in rev_delta_cuisine_dict.items()}\nrev_delta_cuisine_dict = {key: {v['cuisine_style_count']: v['reviews_date_delta'] for k, v in rev_delta_cuisine_dict[key].items()} for key, value in rev_delta_cuisine_dict.items()}\n\n\nrev_delta_max_cuisine_dict = {}\nfor city in model_data.city.unique():\n    rev_delta_max_cuisine_dict.update({city: {'cuisine_style_count': model_data.loc[(model_data['city']==city)].groupby('cuisine_style_count')['reviews_date_delta_max'].median().reset_index().to_dict('index')}})\n        \nrev_delta_max_cuisine_dict = {k: v['cuisine_style_count'] for k, v in rev_delta_max_cuisine_dict.items()}\nrev_delta_max_cuisine_dict = {key: {v['cuisine_style_count']: v['reviews_date_delta_max'] for k, v in rev_delta_max_cuisine_dict[key].items()} for key, value in rev_delta_max_cuisine_dict.items()}\n\n    \ndf_test['reviews_date_delta_old'] = df_test['reviews_date_delta']\ndf_test['reviews_date_delta_max_old'] = df_test['reviews_date_delta_max']\n\ndf_test['reviews_date_delta'] = df_test.apply(lambda x: rev_delta_cuisine_dict[x['city']][x['cuisine_style_count']] if math.isnan(x['reviews_date_delta_old'])==True else x['reviews_date_delta'], axis=1)\ndf_test['reviews_date_delta_max'] = df_test.apply(lambda x: rev_delta_max_cuisine_dict[x['city']][x['cuisine_style_count']] if math.isnan(x['reviews_date_delta_max_old'])==True else x['reviews_date_delta_max'], axis=1)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:50:59.126847Z","iopub.execute_input":"2023-05-22T06:50:59.127195Z","iopub.status.idle":"2023-05-22T06:51:30.431088Z","shell.execute_reply.started":"2023-05-22T06:50:59.127133Z","shell.execute_reply":"2023-05-22T06:51:30.429965Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"NaNs processing started\n","output_type":"stream"}]},{"cell_type":"code","source":"# FEATURE ENGINEERING\n    \nprint('Feature processing started')\n\n# datasets' dividing\ndf_test['cuisine_style_count_old'] = df_test['cuisine_style'].dropna().apply(lambda x: len(x))\ndf_test['rest_type_count_old'] = df_test['rest_type_old'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['area_food_count_old'] = df_test['area_food_old'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['country_food_count_old'] = df_test['country_food_old'].dropna().apply(lambda x: len(x.split(', ')))\ndf_test['spcialities_count_old'] = df_test['spcialities_old'].dropna().apply(lambda x: len(x.split(', ')))\n\n    \nfeatures_dict = {'common_features': ['rating', 'city', 'cuisine_style', 'ranking', 'city_count'],\n                 'old_features': ['price_range_old', 'number_of_reviews_old', 'cuisine_style_count_old'],\n                 'new_features': ['price_range', 'number_of_reviews', 'cuisine_style_count'],\n                 'add_com_features': ['chain', 'chain_scale', 'name_city_count'],\n                 'add_old_features': ['rest_type_old', 'area_food_old', 'country_food_old', 'spcialities_old',\n                                      'rest_type_count_old', 'area_food_count_old', 'country_food_count_old', 'spcialities_count_old',\n                                      'reviews_date_delta_old', 'reviews_date_delta_max_old'\n                                     ],\n                 'add_new_features': ['rest_type', 'area_food', 'country_food', 'spcialities',\n                                      'rest_type_count', 'area_food_count', 'country_food_count', 'spcialities_count', \n                                      'reviews_date_delta', 'reviews_date_delta_max'\n                                     ],\n                 'not_relvant': ['restaurant_id', 'reviews', 'url_ta', 'id_ta',\n                                 'name', 'region', 'g_code', 'gcode_count', \n                                 'reviews_date', 'reviews_date_last', 'reviews_text',\n                                ]\n                  }\n\nprint('Data columns count:', len(list(df_test.columns)))\ndf_test['ranking_city_scaled'] = df_test.apply(lambda x: round(x['ranking']/x['city_count'], 2), axis=1)\n\n    \n# normalization\n\n# since the samples are balanced, we can normalize ranking as follows: \ndf_test['ranking_norm'] = df_test.groupby('city')['ranking'].transform(lambda x: (x-x.min())/(x.max()-x.min()))\ndf_test['ranking_norm_log'] = df_test['ranking_norm'].apply(lambda x: np.log(x+1))\n\ndf_test['ranking_log'] = df_test['ranking'].apply(lambda x: np.log(x))\ndf_test['ranking_log_norm'] = df_test.groupby('city')['ranking_log'].transform(lambda x: (x-x.min())/(x.max()-x.min()))\ndf_test.drop('ranking_log', axis=1, inplace=True)\n\n    \n    \nfrom sklearn.preprocessing import MinMaxScaler\n\nfor col in ['number_of_reviews_old', 'reviews_date_delta_old', 'reviews_date_delta_max_old']:\n    scaler = MinMaxScaler()\n    col_train = scaler.fit_transform(np.array(model_data[col]).reshape(-1, 1))\n    col_test = scaler.transform(np.array(df_test[col]).reshape(-1, 1))\n    \n    indexes_test = pd.RangeIndex(start=0, stop=len(col_test))\n    \n    new_col_df = pd.DataFrame(data=col_test, index=indexes_test, columns=[col+'_norm'])\n    \n    df_test = pd.concat([df_test, new_col_df], axis=1)\n\n    \nfeatures_dict.update({'norm_features': list(df_test.columns)[45:52]})\nprint('Data columns count:', len(list(df_test.columns)))\n\n\n\n# statistics\n    \nprint('Statistic features creating started')\n    \n# For some numeric features, we will calculate statistics on the bundle city & categorical feature\ncombinations = list(product(['ranking'], ['price_range', 'chain_scale'], ['mean'])) # cuisine_style\nfor comb in combinations:\n    #              get_stat_dict(data, cat, num, stat)\n    cat_num_dict = get_stat_dict(model_data, comb[1], comb[0], comb[2])\n    df_test['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])] = df_test.apply(lambda x: cat_num_dict[x['city']][x[str(comb[1])]] if x['city'] in list(cat_num_dict.keys()) and x[str(comb[1])] in list(cat_num_dict[x['city']].keys()) and math.isnan(x[str(comb[1])])==False and math.isnan(x[str(comb[0])])==False else np.nan, axis=1)\n\nfor comb in combinations:\n    #              get_stat_dict(data, cat, num, stat)\n    cat_num_dict = get_stat_dict(df_test, comb[1], comb[0], comb[2])\n    df_test['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])] = df_test.apply(lambda x: cat_num_dict[x['city']][x[str(comb[1])]] if math.isnan(x['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])])==True and x['city'] in list(cat_num_dict.keys()) and x[str(comb[1])] in list(cat_num_dict[x['city']].keys()) and math.isnan(x[str(comb[1])])==False and math.isnan(x[str(comb[0])])==False else x['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])], axis=1)\n\n\ncombinations = list(product(['number_of_reviews', 'reviews_date_delta', 'reviews_date_delta_max'], ['price_range', 'chain_scale'], ['median'])) # cuisine_style\nfor comb in combinations:\n    #              get_stat_dict(data, cat, num, stat)\n    cat_num_dict = get_stat_dict(model_data, comb[1], comb[0], comb[2])\n    df_test['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])] = df_test.apply(lambda x: cat_num_dict[x['city']][x[str(comb[1])]] if x['city'] in list(cat_num_dict.keys()) and x[str(comb[1])] in list(cat_num_dict[x['city']].keys()) and math.isnan(x[str(comb[1])])==False and math.isnan(x[str(comb[0])])==False else np.nan, axis=1)\n\nfor comb in combinations:\n    #              get_stat_dict(data, cat, num, stat)\n    cat_num_dict = get_stat_dict(df_test, comb[1], comb[0], comb[2])\n    df_test['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])] = df_test.apply(lambda x: cat_num_dict[x['city']][x[str(comb[1])]] if math.isnan(x['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])])==True and x['city'] in list(cat_num_dict.keys()) and x[str(comb[1])] in list(cat_num_dict[x['city']].keys()) and math.isnan(x[str(comb[1])])==False and math.isnan(x[str(comb[0])])==False else x['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])], axis=1)\n\n    \ncombinations = list(product(['rating'], ['price_range', 'chain_scale', 'cuisine_style_count'], ['mean'])) # cuisine_style\nfor comb in combinations:\n    #              get_stat_dict(data, cat, num, stat)\n    cat_num_dict = get_stat_dict(model_data, comb[1], comb[0], comb[2])\n    df_test['_'.join(['city', str(comb[0]), str(comb[1]), str(comb[2])])] = df_test.apply(lambda x: cat_num_dict[x['city']][x[str(comb[1])]] if x['city'] in list(cat_num_dict.keys()) and x[str(comb[1])] in list(cat_num_dict[x['city']].keys()) and math.isnan(x[str(comb[1])])==False else np.nan, axis=1)\n\n    \nfeatures_dict.update({'stat_features': list(df_test.columns)[52:63]})\nprint('Data columns count:', len(list(df_test.columns)))\n    \n    \n    \n# additional features\n\n# city can be represented, including the number of chains, as well as 'cheap', 'medium', 'expensive' restaurants\ncity_chain_dict = pd.DataFrame({'city': sorted(model_data.city.unique()),\n                                'chain': model_data.loc[(model_data['chain']==1)].groupby('city').chain.value_counts().values\n                                }).set_index('city').to_dict('index')\n\ndf_test['city_chain'] = df_test['city'].dropna().apply(lambda x: city_chain_dict[x]['chain'])\n\n# 'cheap', 'medium', 'expensive'\ncity_price_range_dict = pd.DataFrame({'city': sorted(model_data.city.unique()),\n                                      'cheap': model_data.loc[(model_data['price_range']==1.0)].groupby('city').price_range.value_counts().values,\n                                      'medium': model_data.loc[(model_data['price_range']==2.5)].groupby('city').price_range.value_counts().values,\n                                      'expensive': model_data.loc[(model_data['price_range']==4.0)].groupby('city').price_range.value_counts().values,\n                                      }).set_index('city').to_dict('index')\n\ndf_test['city_cheap'] = df_test['city'].dropna().apply(lambda x: city_price_range_dict[x]['cheap'])\ndf_test['city_medium'] = df_test['city'].dropna().apply(lambda x: city_price_range_dict[x]['medium'])\ndf_test['city_expensive'] = df_test['city'].dropna().apply(lambda x: city_price_range_dict[x]['expensive'])\n\n\n# Let's reduce the parametrs correlated with name_count\ndf_test['city_chain_scaled'] = df_test.apply(lambda x: x['city_chain']/x['city_count'], axis=1)\ndf_test['city_cheap_scaled'] = df_test.apply(lambda x: x['city_cheap']/x['city_count'], axis=1)\ndf_test['city_medium_scaled'] = df_test.apply(lambda x: x['city_medium']/x['city_count'], axis=1)\ndf_test['city_expensive_scaled'] = df_test.apply(lambda x: x['city_expensive']/x['city_count'], axis=1)\ndf_test['rev_num_city_scaled_old'] = df_test.apply(lambda x: round(x['number_of_reviews_old']/x['city_count'], 2) if math.isnan(x['number_of_reviews_old'])==False else np.nan, axis=1)\n\n    \n# reviews_text\npos_list = list(set(lists_dict['pos_list']))\nneg_list = list(set(lists_dict['neg_list']))\n\n# count the number of positive and negative words in the reviews\ndf_test['reviews_words_list'] = df_test['reviews_text'].dropna().apply(get_words_list)\ndf_test['reviews_pos_score'] = df_test['reviews_words_list'].dropna().apply(get_positive_score)\ndf_test['reviews_neg_score'] = df_test['reviews_words_list'].dropna().apply(get_negative_score)\ndf_test = df_test.drop('reviews_words_list', axis=1)\n\nfeatures_dict.update({'count_features': list(df_test.columns)[63:74]})\nprint('Data columns count:', len(list(df_test.columns)))\n    \n    \n# Polynomial Features\n    \nprint('Polynomial features creating started')\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\nP = df_test[['ranking', 'city_count', 'number_of_reviews_old']].copy().fillna(0)\npoly = PolynomialFeatures(2) # , interaction_only=True\nP_poly = poly.fit_transform(P)\n\nP_poly_df = pd.DataFrame(P_poly,\n                         columns = ['1', 'ranking', 'city_count', 'number_of_reviews_old', \n                                    'ranking^2', 'ranking*city_count', 'ranking*number_of_reviews_old',\n                                    'city_count^2', 'city_count*number_of_reviews_old', 'number_of_reviews_old^2'\n                                   ]\n                         )\npoly_features = list(P_poly_df.columns)[4:] # 6\n\ndf_test = pd.concat([df_test, P_poly_df[poly_features]], axis=1)\ndf_test['ranking_sqrt'] = df_test['ranking'].dropna().apply(lambda x: np.sqrt(x))\n\nfeatures_dict.update({'nlarge_poly_features': list(df_test.columns)[74:81]})\n\n\nP = df_test[['ranking_city_scaled', 'number_of_reviews_old', 'reviews_date_delta_max_old']].copy().fillna(0)\npoly = PolynomialFeatures(2) # , interaction_only=True\nP_poly = poly.fit_transform(P)\n\nP_poly_df = pd.DataFrame(P_poly,\n                         columns = ['1', 'ranking_city_scaled', 'number_of_reviews_old', 'reviews_date_delta_max_old', \n                                    'ranking_city_scaled^2', 'ranking_city_scaled*number_of_reviews_old', 'ranking_city_scaled*reviews_date_delta_max_old',\n                                    'number_of_reviews_old^2', 'number_of_reviews_old*reviews_date_delta_max_old', 'reviews_date_delta_max_old^2'\n                                   ]\n                         )\npoly_features = list(P_poly_df.columns)[4:]\n\ndf_test = pd.concat([df_test, P_poly_df[poly_features]], axis=1)\n\nfeatures_dict.update({'other_poly_features': list(df_test.columns)[81:87]})\nprint('Data columns count:', len(list(df_test.columns)))\n\n    \n    \n# Dummy\n    \n    \nprint('Dummy features creating started')\n\n# Cuisine Style\n\n# city - cuisine_style\ncity_style = model_data.groupby('city')['cuisine_style'].apply(list).reset_index()\ncity_style['cuisine_style'] = city_style['cuisine_style'].apply(cuisine_count_dict)\ncity_style_dict_1 = city_style.set_index('city').to_dict('index')\ncity_style_dict_1 = {k: v['cuisine_style'] for k, v in city_style_dict_1.items()}\n# 'Amsterdam': {'European': 501, 'Vegetarian Friendly': 469, 'Dutch': 286, ... }\n\ncity_style = df_test.groupby('city')['cuisine_style'].apply(list).reset_index()\ncity_style['cuisine_style'] = city_style['cuisine_style'].apply(cuisine_count_dict)\ncity_style_dict_0 = city_style.set_index('city').to_dict('index')\ncity_style_dict_0 = {k: v['cuisine_style'] for k, v in city_style_dict_0.items()}\n\n\nstyle_list = []\nfor cuisine in model_data['cuisine_style'].copy().dropna():\n    for style in cuisine:\n        if not(style in style_list):\n            style_list.append(style)\n        \ndf_test['cuisine_style'] = df_test['cuisine_style'].fillna('-')\n\n# dummy features with counts\nfor item in style_list:\n    df_test['_'.join([str(item), 'count'])] = df_test.apply(lambda x: city_style_dict_1[x['city']][item] if item in x['cuisine_style'] and item in city_style_dict_1[x['city']] else (city_style_dict_0[x['city']][item] if item in x['cuisine_style'] and item in city_style_dict_0[x['city']] else 0), axis=1)\n\nfeatures_dict.update({'cuisine_count_dummy': list(df_test.columns)[87:]})\nprint('Data columns count:', len(list(df_test.columns)))\n    \n\n# city\n\nn_col = len(list(df_test.columns))\ndf_test = pd.get_dummies(df_test, columns=['city'], dummy_na=False)\n\nfeatures_dict.update({'city_dummy': list(df_test.columns)[n_col-1:]})\nprint('Data columns count:', len(list(df_test.columns)))\nfeatures_dict.update({'common_features': remove_elments(features_dict['common_features'], ['city'])})\n    \n    \n    \n# data for model\n\n\n# all additional with statistics & 3 norm & 3 large + 3 other polynomial without original & cuisine count + city dummy with NaNs\ndata_num = df_test[remove_elments(get_data_columns([get_data_columns_dict(['common_features', 'old_features', 'add_com_features', 'add_old_features', 'count_features', 'stat_features', 'nlarge_poly_features', 'other_poly_features', 'cuisine_count_dummy', 'city_dummy']), ['number_of_reviews_old_norm', 'reviews_date_delta_old_norm', 'reviews_date_delta_max_old_norm']]), ['ranking_sqrt', 'ranking', 'city_count', 'number_of_reviews_old', 'reviews_date_delta_max_old'])].select_dtypes(include='number').copy()\ndata_num = data_num.fillna(0)                                               \n\ndata_num.to_csv('data_for_model.csv', index=False)\n    \n    \n    #return data_num\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:51:30.432832Z","iopub.execute_input":"2023-05-22T06:51:30.433185Z","iopub.status.idle":"2023-05-22T06:53:25.597521Z","shell.execute_reply.started":"2023-05-22T06:51:30.433133Z","shell.execute_reply":"2023-05-22T06:53:25.596682Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Feature processing started\nData columns count: 45\nData columns count: 52\nStatistic features creating started\nData columns count: 63\nData columns count: 74\nPolynomial features creating started\nData columns count: 87\nDummy features creating started\nData columns count: 143\nData columns count: 173\n","output_type":"stream"}]},{"cell_type":"code","source":"data_num.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:53:25.598777Z","iopub.execute_input":"2023-05-22T06:53:25.599226Z","iopub.status.idle":"2023-05-22T06:53:25.625993Z","shell.execute_reply.started":"2023-05-22T06:53:25.599177Z","shell.execute_reply":"2023-05-22T06:53:25.624891Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nColumns: 137 entries, rating to reviews_date_delta_max_old_norm\ndtypes: float64(42), int64(64), uint8(31)\nmemory usage: 8.4 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data_num.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T06:53:25.628210Z","iopub.execute_input":"2023-05-22T06:53:25.628556Z","iopub.status.idle":"2023-05-22T06:53:25.667839Z","shell.execute_reply.started":"2023-05-22T06:53:25.628490Z","shell.execute_reply":"2023-05-22T06:53:25.666642Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"      rating  price_range_old  cuisine_style_count_old  chain  chain_scale  \\\n8775       0              0.0                      0.0      0            1   \n6235       0              2.5                      1.0      0            1   \n8134       0              2.5                      5.0      0            1   \n5775       0              2.5                      2.0      0            1   \n4937       0              2.5                      2.0      0            1   \n\n      name_city_count  rest_type_count_old  area_food_count_old  \\\n8775                1                  0.0                  0.0   \n6235                1                  1.0                  0.0   \n8134                1                  2.0                  1.0   \n5775                1                  0.0                  1.0   \n4937                1                  0.0                  1.0   \n\n      country_food_count_old  spcialities_count_old  ...  city_Paris  \\\n8775                     0.0                    0.0  ...           1   \n6235                     0.0                    0.0  ...           0   \n8134                     1.0                    1.0  ...           1   \n5775                     1.0                    0.0  ...           0   \n4937                     1.0                    0.0  ...           0   \n\n      city_Prague  city_Rome  city_Stockholm  city_Vienna  city_Warsaw  \\\n8775            0          0               0            0            0   \n6235            0          0               0            1            0   \n8134            0          0               0            0            0   \n5775            0          0               0            0            1   \n4937            1          0               0            0            0   \n\n      city_Zurich  number_of_reviews_old_norm  reviews_date_delta_old_norm  \\\n8775            0                    0.000518                     0.000000   \n6235            0                    0.005591                     0.004054   \n8134            0                    0.009836                     0.007172   \n5775            0                    0.001864                     0.055815   \n4937            0                    0.001035                     0.016526   \n\n      reviews_date_delta_max_old_norm  \n8775                         0.000000  \n6235                         0.029452  \n8134                         0.027080  \n5775                         0.041510  \n4937                         0.117612  \n\n[5 rows x 137 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>price_range_old</th>\n      <th>cuisine_style_count_old</th>\n      <th>chain</th>\n      <th>chain_scale</th>\n      <th>name_city_count</th>\n      <th>rest_type_count_old</th>\n      <th>area_food_count_old</th>\n      <th>country_food_count_old</th>\n      <th>spcialities_count_old</th>\n      <th>...</th>\n      <th>city_Paris</th>\n      <th>city_Prague</th>\n      <th>city_Rome</th>\n      <th>city_Stockholm</th>\n      <th>city_Vienna</th>\n      <th>city_Warsaw</th>\n      <th>city_Zurich</th>\n      <th>number_of_reviews_old_norm</th>\n      <th>reviews_date_delta_old_norm</th>\n      <th>reviews_date_delta_max_old_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8775</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000518</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6235</th>\n      <td>0</td>\n      <td>2.5</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.005591</td>\n      <td>0.004054</td>\n      <td>0.029452</td>\n    </tr>\n    <tr>\n      <th>8134</th>\n      <td>0</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.009836</td>\n      <td>0.007172</td>\n      <td>0.027080</td>\n    </tr>\n    <tr>\n      <th>5775</th>\n      <td>0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.001864</td>\n      <td>0.055815</td>\n      <td>0.041510</td>\n    </tr>\n    <tr>\n      <th>4937</th>\n      <td>0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.001035</td>\n      <td>0.016526</td>\n      <td>0.117612</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 137 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/bella-k-sf-tripadvisor-rating-best-model/best_model.pkl', 'rb') as pkl_file:\n    best_model = pickle.load(pkl_file)\n\nbest_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_num = data_num.drop('rating', axis=1)\npredict_submission = best_model.predict(data_num)\npredict_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rounding predict with pitch 0.5\npredict_submission_round = []\nfor item in predict_submission:\n    predict_submission_round.append(round(item/0.5)*0.5)\n\npredict_submission_array = np.asarray(predict_submission_round)\npredict_submission_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submision","metadata":{}},{"cell_type":"code","source":"sample_submission.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['Rating'] = predict_submission_array\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}